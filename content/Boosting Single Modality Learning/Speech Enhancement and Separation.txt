# Motivation of audio-visual input
## Signal of multiple speakers in audio is overlpped and hard to be split.
## Signal of multip speakers in visual is isolated.
## Lip movement and speech of the same speaker is consistent.


# Development Route
## In the infancy of these studies, the knowledge-based methods and classical statistical approaches are proposed including Non-negative Matrix Factorization [1], mutual information [2], HMMs [3] and visually-derived Wiener filter [4].
## The deep audio-visual models has demonstrated impressive performance on reconstructing clean speech signal with different forms (e.g., waveform [5] and spectrogram [6]) via the assistance of lip movement [7,8], face clips [9,10,11] and even static face image [12] that provides content-related as well as speaker identity information. 
## Some researchers have proposed denoise methods for the interruption in visual, like the head movement [13] and occlusion [14,15]. 


[1] [Single-Channel Speech Separation using Sparse Non-Negative Matrix Factorization](http://mikkelschmidt.dk/papers/schmidt2006interspeech.pdf)
[2] [Learning Joint Statistical Models for Audio-Visual Fusion and Segregation](https://people.eecs.berkeley.edu/~trevor/papers/fishernips00.pdf)
[3] [Audio-Visual Sound Separation Via Hidden Markov Models](https://papers.nips.cc/paper/2001/hash/d47268e9db2e9aa3827bba3afb7ff94a-Abstract.html) 
[4] [Visually-Derived Wiener Filters for Speech Enhancement](https://ieeexplore.ieee.org/document/4218168)
[5] [Visually Assisted Time-Domain Speech Enhancement](https://ieeexplore.ieee.org/abstract/document/8969244)
[6] [Audio-Visual Speech Enhancement Using Multimodal Deep Convolutional Neural Networks](https://ieeexplore.ieee.org/abstract/document/8323326)
[7] [Visual Speech Enhancement](https://arxiv.org/abs/1711.08789)
[8] [The Conversation: Deep Audio-Visual Speech Enhancement](https://arxiv.org/abs/1804.04121)
[9] [Seeing Through Noise: Visually Driven Speaker Separation And Enhancement](https://ieeexplore.ieee.org/abstract/document/8462527)
[10] [Multimodal SpeakerBeam: Single Channel Target Speech Extraction with Audio-Visual Speaker Clues](https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/1513.pdf)
[11] [Looking Into Your Speech: Learning Cross-Modal Affinity for Audio-Visual Speech Separation](https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Looking_Into_Your_Speech_Learning_Cross-Modal_Affinity_for_Audio-Visual_Speech_CVPR_2021_paper.html?ref=https://githubhelp.com)
[12] [Facefilter: Audio-Visual Speech Separation Using Still Images](https://arxiv.org/abs/2005.07074)
[13] [The Impact of Removing Head Movements on Audio-Visual Speech Enhancement](https://ieeexplore.ieee.org/abstract/document/9746401)
[14] [My Lips Are Concealed: Audio-Visual Speech Enhancement Through Obstructions](https://arxiv.org/abs/1907.04975)
[15] [Robust Unsupervised Audio-Visual Speech Enhancement Using a Mixture of Variational Autoencoders](https://ieeexplore.ieee.org/abstract/document/9053730/)